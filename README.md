# Telegram Scheduler Bot

## Summary
[–ü–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–º. –≤ `CHANGELOG.md`](CHANGELOG.md).

- [API reference](api/docs/index.html)

Closes #123.

## API Contract

The backend consumes the public API contract via the `api/contract` git submodule pinned to the release tag `v1.0.0`.

### Bumping the contract version

1. Sync submodules locally: `git submodule update --init --recursive`.
2. Enter the contract directory: `cd api/contract`.
3. Fetch upstream tags: `git fetch --tags`.
4. Checkout the new release tag (for example `git checkout v1.1.0`).
5. Return to the repository root: `cd ../..`.
6. Stage the updated submodule pointer: `git add api/contract`.
7. Update any documentation or CI checks that reference the previous tag.
8. Commit the change with a message that includes the new contract version.

- **Asset ingestion**. The bot listens to the dedicated recognition channel for new submissions while weather-ready assets live in a separate storage channel. Every photo must contain GPS EXIF data so the bot can resolve the city through Nominatim; authors without coordinates receive an automatic reminder. The pipeline also persists the original EXIF capture timestamp, reuses it when inferring seasonal context and surfaces the recorded date inside the operator info block.
- **Recognition pipeline**. After ingestion the asynchronous job queue schedules a `vision` task that classifies the photo with OpenAI `gpt-4o-mini`, storing the rubric category alongside architectural style, framing notes, seasonal context, detailed weather and detected flowers while respecting per-model daily token quotas configured via environment variables. Before each OpenAI call the bot strictifies the JSON schema‚Äîenforcing `required` lists, propagating `null`-permitted types and setting `additionalProperties: false`‚Äîso `/v1/responses` stays happy when `strict: true` is enabled. Operators should expect nullable values in payload fields that were previously plain primitives. Document uploads are automatically rendered into photo assets before they reach the publishing queue.
- **Rubric automation**. Two daily rubrics are supported out of the box: `flowers` builds its palette strictly from vision outputs, threads daypart weather context into the greeting, preserves per-photo descriptions, injects weather as numeric metrics plus plain-language conditions (no raw provider codes) and spells out the latest `gpt-4o` prompting rules directly in the request payload; `guess_arch` prepares a numbered architecture quiz with optional overlays and weather context. Both rubrics consume recognized assets and clean them up after publishing, auto-initialize on first run and are fully managed through the `/rubrics` inline dashboard.
- **Admin workflow**. Superadmins manage user access, asset channel binding and rubric schedules directly inside Telegram via commands and inline buttons. The admin interface also exposes manual approval queues and quick status messages for rubric runs.
- **Operations guardrails**. OpenAI usage is rate-limited per model, reverse geocoding calls Nominatim with throttling, and each rubric publication is persisted with metadata for auditing through the admin tools.

## Operations

### Healthcheck

- `GET /v1/health` returns the service status for Fly.io/Kubernetes probes, uptime monitoring and e2e tests.
- A `200 OK` response means the SQLite connection, job queue metrics and Telegram `getMe` call all succeeded.
- A `207 Multi-Status` response indicates the bot is running in dry-run mode (`TELEGRAM_BOT_TOKEN=dummy`); Telegram connectivity is skipped but database and queue checks must still pass.
- A `503 Service Unavailable` response surfaces failures from any mandatory dependency and includes a short `error` string in the corresponding `checks` entry.
- The payload includes the resolved `version` (from `APP_VERSION` or `CHANGELOG.md`), UTC timestamp (`now`), process uptime (`uptime_s`), per-check latencies and queue counters (`pending`, `active`, `failed`).
- Each call emits a `HEALTH ... status=...` log line summarizing the probe so operators can trace latency regressions or dependency failures quickly.

### Storage schema

- **devices** ‚Äî stores hardware devices linked to Telegram users. Tracks creation time, optional last_seen timestamp and revocation markers.
- **pairing_tokens** ‚Äî short-lived attach codes that pair a device with a user-defined name. Tokens expire after 10 minutes and are burned on first use.
- **nonces** ‚Äî per-device anti-replay tokens with a 10-minute TTL. Old entries are automatically removed when they expire.
- **uploads** ‚Äî device upload ledger keyed by `(device_id, idempotency_key)` to enforce idempotency. Status transitions follow `queued ‚Üí processing ‚Üí done|failed`; failed rows keep the last error and completed entries remain for at most 24 hours to prevent duplicate retries.

The job queue starts a periodic cleanup task that runs every five minutes. It purges expired pairing tokens and nonces and removes upload rows whose idempotency window (24‚ÄØhours) has elapsed, keeping the database lean without manual intervention.

### Running migrations

Apply schema migrations whenever the service boots or before running tests:

```bash
python - <<'PY'
import sqlite3
from main import apply_migrations

conn = sqlite3.connect("/data/bot.db")
conn.row_factory = sqlite3.Row
apply_migrations(conn)
conn.commit()
conn.close()
PY
```

Replace `/data/bot.db` with the desired SQLite path (for local development you can keep it under `./data`). The same helper executes SQL and Python-based migrations in order and records their application in `schema_migrations`.

## Operator Interface

### Access & governance
- `/start` —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä–≤–æ–≥–æ —Å—É–ø–µ—Ä-–∞–¥–º–∏–Ω–∞ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º.
- `/pending` –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å –∑–∞—è–≤–æ–∫ —Å –∫–Ω–æ–ø–∫–∞–º–∏ `Approve`/`Reject`; —Ä—É—á–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –±–æ–ª—å—à–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.
- `/list_users` –≤—ã–≤–æ–¥–∏—Ç —Ç–µ–∫—É—â–∏—Ö –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ –∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤.
- `/tz` –∑–∞–ø—É—Å–∫–∞–µ—Ç –∫–Ω–æ–ø–æ—á–Ω—ã–π –≤—ã–±–æ—Ä —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –¥–ª—è –ª–∏—á–Ω—ã—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π.
- `/help` –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –ø–∞–º—è—Ç–∫—É —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤—Å–µ—Ö –∫–Ω–æ–ø–æ—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.

### –†—É–±—Ä–∏–∫–∏
- –ü—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë—Ç `flowers` –∏ `guess_arch` –≤ –≤—ã–∫–ª—é—á–µ–Ω–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∏ –±–µ–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π.
- `/rubrics` –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–∞–∂–¥–æ–π —Ä—É–±—Ä–∏–∫–∏. –í–Ω—É—Ç—Ä–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –∫–Ω–æ–ø–∫–∏:
  - `–í–∫–ª—é—á–∏—Ç—å/–í—ã–∫–ª—é—á–∏—Ç—å` ‚Äî –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞.
  - `–ö–∞–Ω–∞–ª` –∏ `–¢–µ—Å—Ç-–∫–∞–Ω–∞–ª` ‚Äî —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ –ø–æ–∏—Å–∫–æ–º, –≤—Å—ë —á–µ—Ä–µ–∑ inline-–∫–Ω–æ–ø–∫–∏.
  - `–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ` ‚Äî –ø–æ—à–∞–≥–æ–≤—ã–π –º–∞—Å—Ç–µ—Ä (–≤—ã–±–æ—Ä –≤—Ä–µ–º–µ–Ω–∏, –º–∏–Ω—É—Ç, –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ –∏ –∫–∞–Ω–∞–ª–∞), –∫–æ—Ç–æ—Ä—ã–π —Ç–∞–∫–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –æ—Ç–∫–ª—é—á–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ—Ç—ã.
  - `‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å` –∏ `üß™ –¢–µ—Å—Ç` ‚Äî —Å–ø–µ—Ä–≤–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è, –∑–∞—Ç–µ–º —Å—Ç–∞–≤—è—Ç –∑–∞–¥–∞—á—É `publish_rubric` –≤ –æ—á–µ—Ä–µ–¥—å –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç –Ω–æ–º–µ—Ä –∑–∞–¥–∞–Ω–∏—è.

### –ú–∞—Å—Ç–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π
- –í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —á–∞—Å—ã, –∑–∞—Ç–µ–º –º–∏–Ω—É—Ç—ã; –≤—ã–±–æ—Ä –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –ø—Ä—è–º–æ –≤ —Ç–µ–∫—Å—Ç–µ –∫–∞—Ä—Ç–æ—á–∫–∏.
- –°–ø–∏—Å–æ–∫ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ –æ—Ç–º–µ—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∞–ª–æ—á–∫–∞–º–∏, –∞ –∫–Ω–æ–ø–∫–∏ `–í—Å–µ`, `–û—á–∏—Å—Ç–∏—Ç—å` –∏ `–ì–æ—Ç–æ–≤–æ` –∑–∞–≤–µ—Ä—à–∞—é—Ç –≤—ã–±–æ—Ä –±–µ–∑ –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞.
- –ü—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ –Ω–∞ ¬´–ö–∞–Ω–∞–ª¬ª –º–∞—Å—Ç–µ—Ä –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç —Ç–æ—Ç –∂–µ –∫–∞–Ω–∞–ª-–ø–∏–∫–µ—Ä, —á—Ç–æ –∏ –∫–∞—Ä—Ç–æ—á–∫–∞ —Ä—É–±—Ä–∏–∫–∏, —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞–∑–∞–¥ –æ–¥–Ω–∏–º –Ω–∞–∂–∞—Ç–∏–µ–º.
- –ö–Ω–æ–ø–∫–∏ `–°–æ—Ö—Ä–∞–Ω–∏—Ç—å` –∏ `–û—Ç–º–µ–Ω–∞` —Ñ–∏–∫—Å–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ —Å—Ä–∞–∑—É –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∫ –∫–∞—Ä—Ç–æ—á–∫–µ —Ä—É–±—Ä–∏–∫–∏.

### –ö–∞–Ω–∞–ª—ã, –ø–æ–≥–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏—è
- `/channels` ‚Äî –∞—É–¥–∏—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤.
- `/set_weather_assets_channel` –∏ `/set_recognition_channel` ‚Äî –∫–Ω–æ–ø–æ—á–Ω—ã–π –≤—ã–±–æ—Ä –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Å—Å–µ—Ç–æ–≤ –∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
- `/setup_weather` –∏ `/list_weather_channels` ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–≥–æ–¥–Ω—ã–º–∏ —Ä–∞—Å—Å—ã–ª–∫–∞–º–∏ —Å –∫–Ω–æ–ø–∫–∞–º–∏ `Run now`/`Stop` –∏ –æ—Ç–º–µ—Ç–∫–∞–º–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞.
- `/weather`, `/history`, `/scheduled` ‚Äî —Å—Ç–∞—Ç—É—Å–Ω—ã–µ –æ—Ç—á—ë—Ç—ã —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç–º–µ–Ω—è—Ç—å –∏–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø—Ä—è–º–æ –∏–∑ inline-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
- `/amber` ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ –Ø–Ω—Ç–∞—Ä–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞, —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–Ω–æ–ø–æ—á–Ω—ã–π.

## User Stories
### Implemented
- **US-1**: As a photographer I can drop photos into the ASSETS channel and the bot ingests them with EXIF validation, notifying me if coordinates are missing so the rubric team always knows the shooting location.
- **US-2**: As a curator I can rely on automatic recognition to pre-fill categories, architecture notes and flower types for every asset, reducing manual tagging before rubric publication.
- **US-3**: As a rubric editor I can configure daily schedules for `flowers` and `guess_arch`, ensure enough classified assets are available and publish them automatically or on demand from Telegram.
- **US-4**: As an administrator I can monitor OpenAI token consumption, review rubric history and audit which assets were consumed, all through the bot‚Äôs inline admin interface.
- **US-5**: As an operations engineer I have a persistent job queue with retry/backoff semantics and manual controls so rubric jobs can be re-run safely without duplicate posts.

### Planned
- Automatic triage for non-photo assets and support for additional rubrics once the asset taxonomy is expanded.

## Environment Setup
### Required environment variables
- `TELEGRAM_BOT_TOKEN` ‚Äì Telegram bot API token used for both webhook registration and admin interactions.
- `WEBHOOK_URL` ‚Äì public HTTPS base used to register `/webhook` on startup.
- `DB_PATH` ‚Äì path to the SQLite database (default `/data/bot.db`).
- `ASSET_STORAGE_DIR` ‚Äì optional override for local media storage. Defaults to `/tmp/bot_assets`; ensure the directory persists across deployments if you expect re-ingestion safeguards.
- `TZ_OFFSET` ‚Äì default timezone applied to schedules until users pick their own offset.
- `SCHED_INTERVAL_SEC` ‚Äì polling cadence for the scheduler loop (default `30`).
- `ASSETS_DEBUG_EXIF` ‚Äì when set to a truthy value, replies to recognized messages with a raw EXIF dump for debugging; defaults to disabled (`0`).
- `PORT` ‚Äì aiohttp listener used when calling `web.run_app`; defaults to `8080` and must align with the port exposed by your hosting provider.
- `4O_API_KEY` ‚Äì key used by the recognition pipeline and rubric copy generators; when missing, related jobs are skipped automatically.
- `OPENAI_DAILY_TOKEN_LIMIT`, `OPENAI_DAILY_TOKEN_LIMIT_GPT_4O` (`OPENAI_DAILY_TOKEN_LIMIT_4O` legacy), `OPENAI_DAILY_TOKEN_LIMIT_GPT_4O_MINI` (`OPENAI_DAILY_TOKEN_LIMIT_4O_MINI` legacy) ‚Äì optional per-model quotas that gate new OpenAI jobs until the next UTC reset.
- `PORT` ‚Äì HTTP port that `web.run_app` listens on (default `8080`). Ensure it matches the port exposed by your proxy or hosting platform (Fly.io, Docker, etc.) so inbound requests reach the app.
- `SUPABASE_URL`, `SUPABASE_KEY` ‚Äì optional credentials for the Supabase project that receives OpenAI token usage events. When configured the bot mirrors SQLite usage rows into the `token_usage` table for centralized analytics, storing `bot`, `model`, prompt/completion/total token counts, `request_id`, `endpoint` (`responses`), strictly JSON-serialized `meta` and timestamp `at` in UTC ISO8601. Each Supabase call also emits a structured `log_token_usage` record ‚Äì identical for successes and failures ‚Äì so log shippers can archive the same payloads even when Supabase is unreachable.

### External services
- **Nominatim** ‚Äì the bot queries `https://nominatim.openstreetmap.org/reverse` and rate-limits calls to one request per second. Set `User-Agent` friendly values in the code if you fork, and consider running your own Nominatim instance for higher throughput.
- **OpenAI Responses API** ‚Äì outbound requests target the `/responses` endpoint; ensure outbound egress is permitted from your hosting environment.
- **Supabase REST** ‚Äì if `SUPABASE_URL`/`SUPABASE_KEY` are set, the bot posts token usage metrics to `rest/v1/token_usage` using the Supabase service role key.

### Local assets & overlays
- Store overlay PNGs for the `guess_arch` rubric inside the directory referenced by the rubric config (default `main.py` ‚Üí `overlays`). Files named `1.png`, `2.png`, etc., are overlaid on published photos; the bot auto-generates numeric badges when files are missing.
- Keep badge graphics roughly within 10‚Äì16% of the shorter photo side. The bot rescales custom overlays into this window before compositing so numbers stay legible without hiding too much of the picture.
- Reserve a safe zone in the top-left corner: standard frames leave 24‚ÄØpx of padding from both edges, while compact assets with a shorter side under 480‚ÄØpx shrink the offset to 12‚ÄØpx. Keep critical details outside this area so auto-numbering never covers the subject.
- Persist asset storage on a volume so ingestion and recognition jobs can retry without re-downloading media. Temporary directories will break overlay generation and duplicate detection after restarts.

## Job Queue and Manual Rubrics
- The SQLite-backed job queue starts automatically when the bot boots, loads due jobs every second and executes handlers concurrently according to `JobQueue(concurrency=...)` settings. Failed jobs retry with exponential backoff up to five attempts before being marked as `failed`. Inspect `jobs_queue` via any SQLite tool for troubleshooting.
- –î–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ—Ç–∫—Ä–æ–π—Ç–µ –∫–∞—Ä—Ç–æ—á–∫—É —Ä—É–±—Ä–∏–∫–∏ –∏ –Ω–∞–∂–º–∏—Ç–µ `‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å` (–±–æ–µ–≤–æ–π —Å–ª–æ—Ç) –∏–ª–∏ `üß™ –¢–µ—Å—Ç` (—Ç–µ—Å—Ç–æ–≤—ã–π —Å–ª–æ—Ç). –¢–µ–ø–µ—Ä—å –±–æ—Ç –Ω–µ –ø—É–±–ª–∏–∫—É–µ—Ç –ø–æ—Å—Ç —Å—Ä–∞–∑—É: –≤ –æ–ø–µ—Ä–∞—Ç–æ—Ä—Å–∫–æ–º —á–∞—Ç–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–≤—å—é –¥—Ä–æ–ø–∞ —Å –∫–Ω–æ–ø–∫–∞–º–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–æ—Ä–æ–¥–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏, –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π, –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–∏, –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –±–æ–µ–≤–æ–π –∏–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–Ω–∞–ª. –ü–æ–≥–æ–¥–Ω—ã–π –±–ª–æ–∫ –≤ –ø—Ä–µ–≤—å—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç, —á—Ç–æ –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—è ‚Äî —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä—è–¥–æ–º —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ –∫–æ–¥–æ–≤. –ü–µ—Ä–µ–¥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å–≤–µ—Ä—è—é—Ç—Å—è —Å —ç—Ç–∏–º README –∏ `docs/weather.md`, —á—Ç–æ–±—ã —Å–æ–±–ª—é–¥–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–æ–≥–æ–¥–Ω–æ–π –ø–æ–¥–∞—á–µ.
- –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –∫–æ—Ä–æ—Ç–∫–æ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é: (1) –∏–Ω–∏—Ü–∏–∏—Ä—É–π—Ç–µ –∑–∞–ø—É—Å–∫ –∫–Ω–æ–ø–∫–æ–π –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–µ; (2) –∏–∑—É—á–∏—Ç–µ –ø—Ä–µ–≤—å—é –≤ —á–∞—Ç–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞; (3) –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ `–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏`, —á—Ç–æ–±—ã —É—Ç–æ—á–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç ‚Äî –≤–≤–æ–¥ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –ø—Ä—è–º–æ –≤ –º–æ–¥–∞–ª—å–Ω–æ–º –æ—Ç–≤–µ—Ç–µ Telegram; (4) –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫–∏ –¥–æ—Å—Ç–∞–≤–∫–∏ –≤ —Ç–µ—Å—Ç–æ–≤—ã–π –∏–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª.
- The job queue deduplicates identical pending payloads, so repeated runs from the same button are safe.
- For ad-hoc publication bypassing the queue entirely, call `publish_rubric` inside the same context; it returns `True` on success and records the run in `posts_history` for later review.

## Deployment
The bot targets Fly.io and exposes a single aiohttp application on port `8080`. Ensure your Fly.io service terminates TLS on port `443` and forwards traffic to the container port so Telegram can reach the webhook. The provided `fly.toml` already contains the required configuration.

### Local run
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Launch the bot:
   ```bash
   python main.py
   ```

Provision Fly.io secrets (`TELEGRAM_BOT_TOKEN`, `WEBHOOK_URL`, `4O_API_KEY`, token limits) before the first deployment.

## Legacy
Historical documentation for the weather scheduler, including sea temperature handling and template placeholders, now lives in `docs/weather.md`. Those features remain in the codebase for backward compatibility but are no longer part of the primary rubric workflow.
