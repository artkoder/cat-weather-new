# Telegram Scheduler Bot

## Summary
[–ü–æ–ª–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å–º. –≤ `CHANGELOG.md`](CHANGELOG.md).

- [API reference](api/docs/index.html)

Closes #123.

## API Contract

The backend consumes the public API contract via the `api/contract` git submodule pinned to the release tag `v1.0.0`. The
canonical OpenAPI document lives at `api/contract/openapi/openapi.yaml`; keep the repository free from alternative copies so the
contract stays single-sourced.

### Bumping the contract version

1. Sync submodules locally: `git submodule update --init --recursive`.
2. Enter the contract directory: `cd api/contract`.
3. Fetch upstream tags: `git fetch --tags`.
4. Checkout the new release tag (for example `git checkout v1.1.0`).
5. Return to the repository root: `cd ../..`.
6. Stage the updated submodule pointer: `git add api/contract`.
7. Update any documentation or CI checks that reference the previous tag.
8. Commit the change with a message that includes the new contract version.

### Working with the OpenAPI spec

- **Render HTML docs**. Bundle the latest contract into `api/docs/index.html` with
  `npx @redocly/cli build-docs api/contract/openapi/openapi.yaml -o api/docs/index.html` and open the resulting file locally or serve
  it from `/api/docs`. The HTML shell references the submodule path directly, so no copy of the YAML is required.
- **Lint**. Run `npx @redocly/cli lint api/contract/openapi/openapi.yaml` (or an equivalent Spectral command) to validate changes before
  publishing a new contract version.
- **CI guard**. The automation fails fast if a local OpenAPI spec appears outside `api/contract/`; adjust CI only when the
  contract repository layout changes.

- **Asset ingestion**. The bot listens to the dedicated recognition channel for new submissions while weather-ready assets live in a separate storage channel. Every photo must contain GPS EXIF data so the bot can resolve the city through Nominatim; authors without coordinates receive an automatic reminder. The pipeline also persists the original EXIF capture timestamp, reuses it when inferring seasonal context and surfaces the recorded date inside the operator info block.
- **Recognition pipeline**. After ingestion the asynchronous job queue schedules a `vision` task that classifies the photo with OpenAI `gpt-4o-mini`, storing the rubric category alongside architectural style, framing notes, seasonal context, detailed weather and detected flowers while respecting per-model daily token quotas configured via environment variables. Before each OpenAI call the bot strictifies the JSON schema‚Äîenforcing `required` lists, propagating `null`-permitted types and setting `additionalProperties: false`‚Äîso `/v1/responses` stays happy when `strict: true` is enabled. Operators should expect nullable values in payload fields that were previously plain primitives. Document uploads are automatically rendered into photo assets before they reach the publishing queue.
- **Rubric automation**. Two daily rubrics are supported out of the box: `flowers` builds its palette strictly from vision outputs, threads daypart weather context into the greeting, preserves per-photo descriptions, injects weather as numeric metrics plus plain-language conditions (no raw provider codes) and spells out the latest `gpt-4o` prompting rules directly in the request payload; `guess_arch` prepares a numbered architecture quiz with optional overlays and weather context. Both rubrics consume recognized assets and clean them up after publishing, auto-initialize on first run and are fully managed through the `/rubrics` inline dashboard.
- **Admin workflow**. Superadmins manage user access, asset channel binding and rubric schedules directly inside Telegram via commands and inline buttons. The admin interface also exposes manual approval queues and quick status messages for rubric runs.
- **Operations guardrails**. OpenAI usage is rate-limited per model, reverse geocoding calls Nominatim with throttling, and each rubric publication is persisted with metadata for auditing through the admin tools.

## Operations

### Healthcheck

- `GET /v1/health` returns the service status for Fly.io/Kubernetes probes, uptime monitoring and e2e tests.
- A `200 OK` response means the SQLite connection, job queue metrics and Telegram `getMe` call all succeeded.
- A `207 Multi-Status` response indicates the bot is running in dry-run mode (`TELEGRAM_BOT_TOKEN=dummy`); Telegram connectivity is skipped but database and queue checks must still pass.
- A `503 Service Unavailable` response surfaces failures from any mandatory dependency and includes a short `error` string in the corresponding `checks` entry.
- The payload includes the resolved `version` (from `APP_VERSION` or `CHANGELOG.md`), UTC timestamp (`now`), process uptime (`uptime_s`), per-check latencies and queue counters (`pending`, `active`, `failed`).
- Each call emits a `HEALTH ... status=...` log line summarizing the probe so operators can trace latency regressions or dependency failures quickly.

### Observability

- Logs are structured JSON by default and include `ts`, `level`, `msg`, `request_id`, `route`, `method`, `status`, `duration_ms`, `device_id`, `job`, `upload_id` and `ip` when available. Set `LOG_FORMAT=pretty` locally to switch to a human-friendly formatter.
- Sensitive tokens are redacted automatically (`X-Signature`, `secret`, `token`, `authorization` fields are replaced with `***`). Use `LOG_LEVEL` to increase verbosity during incident response.
- The `/metrics` endpoint exposes Prometheus metrics (HTTP counters/histograms, HMAC failures, upload/job counters, queue depth, storage bytes and health timings) and default process/platform collectors. Access is guarded by the rate-limit middleware (default 5 requests/minute per IP) and requires `ALLOWLIST_CIDR` to include the caller address.

### E2E

- `scripts/e2e_attach_upload.py` drives the staging attach ‚Üí upload ‚Üí processed smoke test used by CI.
- The helper CLI (`python -m tools.e2e create-pairing`) mints a pairing code when `E2E_MODE=true` so the end-to-end workflow never depends on Telegram.
- The script synthesizes a 1√ó1 PNG image at runtime (no binary fixtures) and reuses the exact multipart payload for both HMAC signing and the upload request.
- `tests/test_e2e.py` wraps the script for pytest and is marked with `@pytest.mark.e2e`; it skips automatically unless the `E2E_*` variables are configured.

### Storage schema

- **devices** ‚Äî stores hardware devices linked to Telegram users. Tracks creation time, optional last_seen timestamp and revocation markers.
- **pairing_tokens** ‚Äî short-lived attach codes that pair a device with a user-defined name. Tokens expire after 10 minutes and are burned on first use.
- **nonces** ‚Äî per-device anti-replay tokens with a 10-minute TTL. Old entries are automatically removed when they expire.
- **uploads** ‚Äî device upload ledger keyed by `(device_id, idempotency_key)` to enforce idempotency. Status transitions follow `queued ‚Üí processing ‚Üí done|failed`; failed rows keep the last error and completed entries remain for at most 24 hours to prevent duplicate retries.

The job queue starts a periodic cleanup task that runs every five minutes. It purges expired pairing tokens and nonces and removes upload rows whose idempotency window (24‚ÄØhours) has elapsed, keeping the database lean without manual intervention.

### Device secret lifecycle

- **Generating secrets**. During `/v1/devices/attach` the backend issues a 32-byte random secret encoded as lowercase hex. For manual testing you can generate compatible values with `python -c "import secrets; print(secrets.token_hex(32))"`.
- **Client storage**. Mobile clients must persist the `device.id` and `device.secret` pair inside an encrypted store (Android uses `EncryptedSharedPreferences`) and attach them to every signed request via the HMAC headers.
- **Rotation and revoke**. Operators can call `POST /v1/devices/revoke` to invalidate the current secret. The backend immediately rejects signed calls with `device_revoked` forcing the client to repeat the attach flow and pick up the new secret. Secrets can also be proactively rotated by reissuing the attach flow and updating the persisted values on the device.

### Mobile pairing QR codes

- The `/mobile` command posts a pairing card with a QR code so testers can attach new devices without copying the code manually.
- The QR payload encodes the literal string `PAIR:<CODE>`; clients should continue to accept that legacy format even if the mobile app also supports a deeplink variant (for example `catweather://pair?code=<CODE>`).
- Regenerating the card via the inline "üîÑ –ù–æ–≤—ã–π –∫–æ–¥" button follows the same format and preserves the default expiry window shown in the caption.

### Running migrations

Apply schema migrations whenever the service boots or before running tests:

```bash
python - <<'PY'
import sqlite3
from main import apply_migrations

conn = sqlite3.connect("/data/bot.db")
conn.row_factory = sqlite3.Row
apply_migrations(conn)
conn.commit()
conn.close()
PY
```

Replace `/data/bot.db` with the desired SQLite path (for local development you can keep it under `./data`). The same helper executes SQL and Python-based migrations in order and records their application in `schema_migrations`.

## Operator Interface

### Access & governance
- `/start` —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –ø–µ—Ä–≤–æ–≥–æ —Å—É–ø–µ—Ä-–∞–¥–º–∏–Ω–∞ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º.
- `/pending` –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å –∑–∞—è–≤–æ–∫ —Å –∫–Ω–æ–ø–∫–∞–º–∏ `Approve`/`Reject`; —Ä—É—á–Ω–æ–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –±–æ–ª—å—à–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.
- `/list_users` –≤—ã–≤–æ–¥–∏—Ç —Ç–µ–∫—É—â–∏—Ö –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–æ–≤ –∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤.
- `/tz` –∑–∞–ø—É—Å–∫–∞–µ—Ç –∫–Ω–æ–ø–æ—á–Ω—ã–π –≤—ã–±–æ—Ä —á–∞—Å–æ–≤–æ–≥–æ –ø–æ—è—Å–∞ –¥–ª—è –ª–∏—á–Ω—ã—Ö —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π.
- `/help` –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –ø–∞–º—è—Ç–∫—É —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –≤—Å–µ—Ö –∫–Ω–æ–ø–æ—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.

### –†—É–±—Ä–∏–∫–∏
- –ü—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –±–æ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞—ë—Ç `flowers` –∏ `guess_arch` –≤ –≤—ã–∫–ª—é—á–µ–Ω–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∏ –±–µ–∑ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π.
- `/rubrics` –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—Ä—Ç–æ—á–∫–∏ –∫–∞–∂–¥–æ–π —Ä—É–±—Ä–∏–∫–∏. –í–Ω—É—Ç—Ä–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –∫–Ω–æ–ø–∫–∏:
  - `–í–∫–ª—é—á–∏—Ç—å/–í—ã–∫–ª—é—á–∏—Ç—å` ‚Äî –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞.
  - `–ö–∞–Ω–∞–ª` –∏ `–¢–µ—Å—Ç-–∫–∞–Ω–∞–ª` ‚Äî —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ –ø–æ–∏—Å–∫–æ–º, –≤—Å—ë —á–µ—Ä–µ–∑ inline-–∫–Ω–æ–ø–∫–∏.
  - `–î–æ–±–∞–≤–∏—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ` ‚Äî –ø–æ—à–∞–≥–æ–≤—ã–π –º–∞—Å—Ç–µ—Ä (–≤—ã–±–æ—Ä –≤—Ä–µ–º–µ–Ω–∏, –º–∏–Ω—É—Ç, –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ –∏ –∫–∞–Ω–∞–ª–∞), –∫–æ—Ç–æ—Ä—ã–π —Ç–∞–∫–∂–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏–ª–∏ –æ—Ç–∫–ª—é—á–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ—Ç—ã.
  - `‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å` –∏ `üß™ –¢–µ—Å—Ç` ‚Äî —Å–ø–µ—Ä–≤–∞ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∑–∞–ø—Ä–æ—Å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è, –∑–∞—Ç–µ–º —Å—Ç–∞–≤—è—Ç –∑–∞–¥–∞—á—É `publish_rubric` –≤ –æ—á–µ—Ä–µ–¥—å –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç –Ω–æ–º–µ—Ä –∑–∞–¥–∞–Ω–∏—è.

### –ú–∞—Å—Ç–µ—Ä —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–π
- –í—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç —á–∞—Å—ã, –∑–∞—Ç–µ–º –º–∏–Ω—É—Ç—ã; –≤—ã–±–æ—Ä –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –ø—Ä—è–º–æ –≤ —Ç–µ–∫—Å—Ç–µ –∫–∞—Ä—Ç–æ—á–∫–∏.
- –°–ø–∏—Å–æ–∫ –¥–Ω–µ–π –Ω–µ–¥–µ–ª–∏ –æ—Ç–º–µ—á–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≥–∞–ª–æ—á–∫–∞–º–∏, –∞ –∫–Ω–æ–ø–∫–∏ `–í—Å–µ`, `–û—á–∏—Å—Ç–∏—Ç—å` –∏ `–ì–æ—Ç–æ–≤–æ` –∑–∞–≤–µ—Ä—à–∞—é—Ç –≤—ã–±–æ—Ä –±–µ–∑ –≤–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞.
- –ü—Ä–∏ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–∏ –Ω–∞ ¬´–ö–∞–Ω–∞–ª¬ª –º–∞—Å—Ç–µ—Ä –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç —Ç–æ—Ç –∂–µ –∫–∞–Ω–∞–ª-–ø–∏–∫–µ—Ä, —á—Ç–æ –∏ –∫–∞—Ä—Ç–æ—á–∫–∞ —Ä—É–±—Ä–∏–∫–∏, —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –≤–µ—Ä–Ω—É—Ç—å—Å—è –Ω–∞–∑–∞–¥ –æ–¥–Ω–∏–º –Ω–∞–∂–∞—Ç–∏–µ–º.
- –ö–Ω–æ–ø–∫–∏ `–°–æ—Ö—Ä–∞–Ω–∏—Ç—å` –∏ `–û—Ç–º–µ–Ω–∞` —Ñ–∏–∫—Å–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏ —Å—Ä–∞–∑—É –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∫ –∫–∞—Ä—Ç–æ—á–∫–µ —Ä—É–±—Ä–∏–∫–∏.

### –ö–∞–Ω–∞–ª—ã, –ø–æ–≥–æ–¥–∞ –∏ –∏—Å—Ç–æ—Ä–∏—è
- `/channels` ‚Äî –∞—É–¥–∏—Ç –ø–æ–¥–∫–ª—é—á—ë–Ω–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤.
- `/set_weather_assets_channel` –∏ `/set_recognition_channel` ‚Äî –∫–Ω–æ–ø–æ—á–Ω—ã–π –≤—ã–±–æ—Ä –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Å—Å–µ—Ç–æ–≤ –∏ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
- `/setup_weather` –∏ `/list_weather_channels` ‚Äî —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–≥–æ–¥–Ω—ã–º–∏ —Ä–∞—Å—Å—ã–ª–∫–∞–º–∏ —Å –∫–Ω–æ–ø–∫–∞–º–∏ `Run now`/`Stop` –∏ –æ—Ç–º–µ—Ç–∫–∞–º–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞.
- `/weather`, `/history`, `/scheduled` ‚Äî —Å—Ç–∞—Ç—É—Å–Ω—ã–µ –æ—Ç—á—ë—Ç—ã —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –æ—Ç–º–µ–Ω—è—Ç—å –∏–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—å –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø—Ä—è–º–æ –∏–∑ inline-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
- `/amber` ‚Äî –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ä–∞–∑–¥–µ–ª –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ –Ø–Ω—Ç–∞—Ä–Ω–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞, —Ç–∞–∫–∂–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∫–Ω–æ–ø–æ—á–Ω—ã–π.

## User Stories
### Implemented
- **US-1**: As a photographer I can drop photos into the ASSETS channel and the bot ingests them with EXIF validation, notifying me if coordinates are missing so the rubric team always knows the shooting location.
- **US-2**: As a curator I can rely on automatic recognition to pre-fill categories, architecture notes and flower types for every asset, reducing manual tagging before rubric publication.
- **US-3**: As a rubric editor I can configure daily schedules for `flowers` and `guess_arch`, ensure enough classified assets are available and publish them automatically or on demand from Telegram.
- **US-4**: As an administrator I can monitor OpenAI token consumption, review rubric history and audit which assets were consumed, all through the bot‚Äôs inline admin interface.
- **US-5**: As an operations engineer I have a persistent job queue with retry/backoff semantics and manual controls so rubric jobs can be re-run safely without duplicate posts.

### Planned
- Automatic triage for non-photo assets and support for additional rubrics once the asset taxonomy is expanded.

## Environment Setup
### Required environment variables

| Variable | Default | Description |
| --- | --- | --- |
| `TELEGRAM_BOT_TOKEN` | ‚Äì | Telegram bot API token used for webhook registration and admin interactions. |
| `WEBHOOK_URL` | ‚Äì | Public HTTPS base used to register `/webhook` on startup. |
| `DB_PATH` | `/data/bot.db` | SQLite database location. The directory is created automatically when it does not exist. |
| `ASSET_STORAGE_DIR` | `/tmp/bot_assets` | Optional override for on-disk asset cache used by the bot when reposting to Telegram; ensure it survives restarts if you rely on re-ingestion safeguards. |
| `STORAGE_BACKEND` | `local` | Storage driver for mobile uploads. `local` keeps files under `data/uploads`, while `supabase` streams payloads to the bucket configured via `SUPABASE_BUCKET`. Unknown values fall back to `local`. |
| `SUPABASE_BUCKET` | `uploads` | Bucket name used when `STORAGE_BACKEND=supabase`. The bucket must exist in the target Supabase project. |
| `CLEANUP_LOCAL_AFTER_PUBLISH` | `0` | When truthy and `STORAGE_BACKEND=local`, the mobile pipeline deletes the original upload once publishing finishes. Remote storage backends already purge their temporary downloads automatically, and Supabase uploads are unaffected by this flag. |
| `TZ_OFFSET` | `+00:00` | Default timezone applied to schedules until users pick their own offset. |
| `SCHED_INTERVAL_SEC` | `30` | Polling cadence for the scheduler loop. |
| `ASSETS_DEBUG_EXIF` | `0` | When truthy, replies to recognized messages with a raw EXIF dump for debugging. |
| `VISION_ENABLED` | ‚Äì | Toggles the OpenAI vision classification step for new uploads. When disabled the job skips recognition entirely. |
| `OPENAI_VISION_MODEL` | ‚Äì | Model passed to the OpenAI Responses API for vision classification. Required whenever `VISION_ENABLED` is truthy. |
| `MAX_IMAGE_SIDE` | ‚Äì | Optional upper bound (pixels) for the longest photo side. Downscales recognition/preview copies while preserving the original upload. |
| `PORT` | `8080` | HTTP port that `web.run_app` listens on. Must align with the port exposed by the hosting platform. |
| `4O_API_KEY` | ‚Äì | API key used by the recognition pipeline and rubric copy generators; related jobs are skipped automatically when missing. |
| `OPENAI_DAILY_TOKEN_LIMIT`<br>`OPENAI_DAILY_TOKEN_LIMIT_GPT_4O` (`OPENAI_DAILY_TOKEN_LIMIT_4O` legacy)<br>`OPENAI_DAILY_TOKEN_LIMIT_GPT_4O_MINI` (`OPENAI_DAILY_TOKEN_LIMIT_4O_MINI` legacy) | ‚Äì | Optional per-model daily token quotas that block new OpenAI jobs until the next UTC reset once exhausted. |
| `LOG_LEVEL` | `INFO` | Structured log severity (`DEBUG`, `INFO`, `WARN`, `ERROR`). |
| `LOG_FORMAT` | `json` | Switch to `pretty` locally for human-friendly logs. |
| `ALLOWLIST_CIDR` | ‚Äì | Comma-separated CIDR ranges allowed to call `/metrics` (and `/_admin` when present). Requests from outside the allow-list receive `403`. |
| `RL_ATTACH_IP_PER_MIN`<br>`RL_ATTACH_USER_PER_MIN`<br>`RL_UPLOADS_PER_MIN`<br>`RL_UPLOAD_STATUS_PER_MIN`<br>`RL_HEALTH_PER_MIN`<br>`RL_METRICS_PER_MIN` | varies | Per-minute request ceilings enforced by the in-memory token bucket. Pair each limit with the corresponding `*_WINDOW_SEC` variable (defaults to 60 seconds) to tune the refill window. |
| `SUPABASE_URL`<br>`SUPABASE_KEY` (or `SUPABASE_ANON_KEY`) | ‚Äì | Supabase credentials. When set, the bot mirrors OpenAI token usage into `rest/v1/token_usage` **and** powers the Supabase storage backend for mobile uploads via `SUPABASE_BUCKET`. Each request logs a `log_token_usage` entry regardless of success. |

> ‚ÑπÔ∏è  Configure the Telegram channel for asset ingestion via the admin bot (for example `/set_weather_assets_channel`). The value is stored in the database (`asset_channel` table) and there is no environment variable override.

### External services
- **Nominatim** ‚Äì the bot queries `https://nominatim.openstreetmap.org/reverse` and rate-limits calls to one request per second. Set `User-Agent` friendly values in the code if you fork, and consider running your own Nominatim instance for higher throughput.
- **OpenAI Responses API** ‚Äì outbound requests target the `/responses` endpoint; ensure outbound egress is permitted from your hosting environment.
- **Supabase REST** ‚Äì if `SUPABASE_URL`/`SUPABASE_KEY` are set, the bot posts token usage metrics to `rest/v1/token_usage` using the Supabase service role key.

### Local assets & overlays
- Store overlay PNGs for the `guess_arch` rubric inside the directory referenced by the rubric config (default `main.py` ‚Üí `overlays`). Files named `1.png`, `2.png`, etc., are overlaid on published photos; the bot auto-generates numeric badges when files are missing.
- Keep badge graphics roughly within 10‚Äì16% of the shorter photo side. The bot rescales custom overlays into this window before compositing so numbers stay legible without hiding too much of the picture.
- Reserve a safe zone in the top-left corner: standard frames leave 24‚ÄØpx of padding from both edges, while compact assets with a shorter side under 480‚ÄØpx shrink the offset to 12‚ÄØpx. Keep critical details outside this area so auto-numbering never covers the subject.
- Persist asset storage on a volume so ingestion and recognition jobs can retry without re-downloading media. Temporary directories will break overlay generation and duplicate detection after restarts.

## Job Queue and Manual Rubrics
- The SQLite-backed job queue starts automatically when the bot boots, loads due jobs every second and executes handlers concurrently according to `JobQueue(concurrency=...)` settings. Failed jobs retry with exponential backoff up to five attempts before being marked as `failed`. Inspect `jobs_queue` via any SQLite tool for troubleshooting.
- –î–ª—è —Ä—É—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –æ—Ç–∫—Ä–æ–π—Ç–µ –∫–∞—Ä—Ç–æ—á–∫—É —Ä—É–±—Ä–∏–∫–∏ –∏ –Ω–∞–∂–º–∏—Ç–µ `‚ñ∂Ô∏è –ó–∞–ø—É—Å—Ç–∏—Ç—å` (–±–æ–µ–≤–æ–π —Å–ª–æ—Ç) –∏–ª–∏ `üß™ –¢–µ—Å—Ç` (—Ç–µ—Å—Ç–æ–≤—ã–π —Å–ª–æ—Ç). –¢–µ–ø–µ—Ä—å –±–æ—Ç –Ω–µ –ø—É–±–ª–∏–∫—É–µ—Ç –ø–æ—Å—Ç —Å—Ä–∞–∑—É: –≤ –æ–ø–µ—Ä–∞—Ç–æ—Ä—Å–∫–æ–º —á–∞—Ç–µ –ø–æ—è–≤–ª—è–µ—Ç—Å—è –ø—Ä–µ–≤—å—é –¥—Ä–æ–ø–∞ —Å –∫–Ω–æ–ø–∫–∞–º–∏ –¥–ª—è –≤—ã–±–æ—Ä–∞ –≥–æ—Ä–æ–¥–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏, –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π, –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø–æ–¥–ø–∏—Å–∏, –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ –±–æ–µ–≤–æ–π –∏–ª–∏ —Ç–µ—Å—Ç–æ–≤—ã–π –∫–∞–Ω–∞–ª. –ü–æ–≥–æ–¥–Ω—ã–π –±–ª–æ–∫ –≤ –ø—Ä–µ–≤—å—é –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç, —á—Ç–æ –∏ –ø—É–±–ª–∏–∫–∞—Ü–∏—è ‚Äî —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —Ä—è–¥–æ–º —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ —É—Å–ª–æ–≤–∏—è–º–∏ –±–µ–∑ –∫–æ–¥–æ–≤. –ü–µ—Ä–µ–¥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã —Å–≤–µ—Ä—è—é—Ç—Å—è —Å —ç—Ç–∏–º README –∏ `docs/weather.md`, —á—Ç–æ–±—ã —Å–æ–±–ª—é–¥–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –ø–æ–≥–æ–¥–Ω–æ–π –ø–æ–¥–∞—á–µ.
- –†—É—á–Ω–æ–π –∑–∞–ø—É—Å–∫ –ø—Ä–æ—Ö–æ–¥–∏—Ç –ø–æ –∫–æ—Ä–æ—Ç–∫–æ–º—É —Å—Ü–µ–Ω–∞—Ä–∏—é: (1) –∏–Ω–∏—Ü–∏–∏—Ä—É–π—Ç–µ –∑–∞–ø—É—Å–∫ –∫–Ω–æ–ø–∫–æ–π –Ω–∞ –∫–∞—Ä—Ç–æ—á–∫–µ; (2) –∏–∑—É—á–∏—Ç–µ –ø—Ä–µ–≤—å—é –≤ —á–∞—Ç–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞; (3) –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –ø–µ—Ä–µ–≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏ `–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏`, —á—Ç–æ–±—ã —É—Ç–æ—á–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç ‚Äî –≤–≤–æ–¥ –æ—Å—É—â–µ—Å—Ç–≤–ª—è–µ—Ç—Å—è –ø—Ä—è–º–æ –≤ –º–æ–¥–∞–ª—å–Ω–æ–º –æ—Ç–≤–µ—Ç–µ Telegram; (4) –≤—ã–±–µ—Ä–∏—Ç–µ –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –∫–Ω–æ–ø–∫–∏ –¥–æ—Å—Ç–∞–≤–∫–∏ –≤ —Ç–µ—Å—Ç–æ–≤—ã–π –∏–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–∞–Ω–∞–ª.
- The job queue deduplicates identical pending payloads, so repeated runs from the same button are safe.
- For ad-hoc publication bypassing the queue entirely, call `publish_rubric` inside the same context; it returns `True` on success and records the run in `posts_history` for later review.

## Deployment
The bot targets Fly.io and exposes a single aiohttp application on port `8080`. Ensure your Fly.io service terminates TLS on port `443` and forwards traffic to the container port so Telegram can reach the webhook. The provided `fly.toml` already contains the required configuration.

### Local run
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Launch the bot:
   ```bash
   python main.py
   ```

Provision Fly.io secrets (`TELEGRAM_BOT_TOKEN`, `WEBHOOK_URL`, `4O_API_KEY`, token limits) before the first deployment.

## Legacy
Historical documentation for the weather scheduler, including sea temperature handling and template placeholders, now lives in `docs/weather.md`. Those features remain in the codebase for backward compatibility but are no longer part of the primary rubric workflow.
